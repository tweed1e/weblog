---
title: "Simulating A/B testing and experiment data"
author: "Jesse Tweedle"
date: '2018-02-20'
slug: simulating-ab-testing-data
categories: ["r", "stats", "ab testing"]
tags: ["r", "stats", "ab testing", "data science interview", "dataset"]
description: ''
image: "https://jesse.tw/images/circle-arrows.png"
---



<div id="simulating-data-is-super-useful-for-testing-methods-and-data-science-interview-prep" class="section level2">
<h2>Simulating data is super useful for testing methods and data science interview prep</h2>
<p>Simulation is a great way to study statistics. If you’re picking up a method for the first time, (e.g., from the <a href="https://www.udacity.com/course/ab-testing--ud257">Udacity AB testing course</a>) it’s too easy to convince yourself you know what’s going on without actually doing the math or programming. For example, when I see binary treatments and outcomes, I wonder “would I get the same answer if I do binomial proportion test vs. logistic regression?” You don’t have to guess (or derive the answer analytically)!</p>
<p>Just simulate it! If you want to practice a method, make a dataset with the desired treatment effect and other characteristics, simulate it, and see if your method gets the right answer back. The tough part with real data and real experiments (and data science interview problems) is that you won’t know the real answer, you just try to implement a method that makes sense and hope you get it right.</p>
<p>There are a million different experiments you can run and a million datasets that represent those experiments, but I’ll try to outline some easy ones to get started.</p>
<div id="basic-binary-treatment-d-continuous-outcome-y-with-error-e" class="section level3">
<h3>Basic: binary treatment (D), continuous outcome (y) with error (e)</h3>
<pre class="r"><code>library(tibble)

N &lt;- 1000    # number of individuals
sigma_e &lt;- 1 # s.d. of error
beta &lt;- 0.1  # effect of treatment

df &lt;- tibble(
  id = seq_len(N), 
  D = rbinom(N, 1, 0.5), # 50% probability of treatment
  e = rnorm(N, 0, sigma_e),
  y = beta * D + e
)</code></pre>
</div>
<div id="basic-with-covariate-binary-treatment-d-continuous-covariate-x-continuous-outcome-y-with-error-e" class="section level3">
<h3>Basic with covariate: binary treatment (D), continuous covariate (X), continuous outcome (y) with error (e)</h3>
<pre class="r"><code>library(tibble)

N &lt;- 1000
sigma_e &lt;- 1
sigma_x &lt;- 1  # s.d. of covariate
beta &lt;- 0.1   
beta_x &lt;- 1   # effect of covariate on outcome

df &lt;- tibble(
  id = seq_len(N), 
  D = rbinom(N, 1, 0.5),  # 50% probability of treatment
  X = rnorm(N, 0, sigma_x),
  e = rnorm(N, 0, sigma_e),
  y = beta * D + beta_x * X + e
)</code></pre>
</div>
<div id="basic-with-binary-outcome-binary-treatment-d-binary-outcome-y-with-error-e" class="section level3">
<h3>Basic with binary outcome: binary treatment (D), binary outcome (y) with error (e)</h3>
<pre class="r"><code>library(tibble)

N &lt;- 1000
sigma_e &lt;- 1
sigma_x &lt;- 1  # variance of covariate
beta &lt;- 0.1 # effect of treatment
beta_x &lt;- 1   # effect of covariate on outcome

df &lt;- tibble(
  id = seq_len(N), 
  D = rbinom(N, 1, 0.5),  # 50% probability of treatment
  e = rnorm(N, 0, sigma_e),
  y = as.integer(beta * D + e &gt;= 0)
  # ^^ you can change the probability of 0 or 1 by changing 
  # the cutoff &#39;&gt;=0&#39; to something else here
)</code></pre>
</div>
<div id="time-series-two-periods-t-binary-treatment-d-continuous-outcome-y-with-autoregressive-error-e" class="section level3">
<h3>Time series: two periods (T), binary treatment (D), continuous outcome (y) with autoregressive error (e)</h3>
<pre class="r"><code>library(dplyr)
library(tibble)
library(tidyr)

N &lt;- 100
T &lt;- 2
ar &lt;- 0.5 # autoregressive parameter
beta &lt;- 0.1

df &lt;- crossing(
    id = seq_len(N),
    t = 1:T
  ) %&gt;%
  group_by(id) %&gt;% 
  mutate(
    e = arima.sim(model = list(ar = ar), n = T),
    # 50% probability of treatment, no treatment if t == 1
    D = ifelse(t == 2, rbinom(1, 1, 0.5), 0),  
    y = beta * D + e
  )</code></pre>
</div>
<div id="website-log-data-click-events-click-multiple-timestamped-sessions-per-user-with-session-treatments-treatment-randomly-assigned-to-users-id" class="section level3">
<h3>Website log data: click events (click), multiple timestamped sessions per user with (session), treatments (treatment) randomly assigned to users (id)</h3>
<pre class="r"><code>library(dplyr)
library(tibble)
library(tidyr)
library(purrr)
library(digest)
library(lubridate)

N &lt;- 1000
start &lt;- ymd_hms(&quot;2018-01-01 0:00:00&quot;, tz = &quot;America/Toronto&quot;)
lambda &lt;- 5 # determines number of events per user
beta &lt;- 0.1
p &lt;- 0.5    # base probability of outcome.

df &lt;- tibble(
              id = seq_len(N), 
              n_events = rpois(N, lambda)
            ) %&gt;% 
      rowwise() %&gt;% 
      mutate(id = digest(id))

# how many seconds in a day? ty lubridate.
spd &lt;- ddays() / dseconds()

# simulate events to add to user data.
events_df &lt;- df %&gt;% 
    mutate(
            events = list(start + dseconds(runif(n_events, 0, (now() - start) / dseconds()))),
            # ^^ randomly sample sessions as the number of seconds from start date, then add to start date
            # change this from runif to get more realistic timestamps, use different timezones to practice
            # cleaning / validating data, etc. etc.
            treatment = rbinom(1, 1, 0.5)
            # ^^ randomly assign treatment to *users*
          ) %&gt;% # end mutate
    ungroup() %&gt;% 
    mutate(events = map(events, as_tibble)) %&gt;% 
    unnest(events) %&gt;% 
    # base probability of click outcome is p, increased by beta if treated
    mutate(click = rbinom(length(treatment), 1, p + beta * treatment)) %&gt;% 
    select(id, session = value, treatment, click) # re-organize

events_df %&gt;% print(n = 5)
## # A tibble: 5,068 x 4
##   id                               session             treatment click
##   &lt;chr&gt;                            &lt;dttm&gt;                  &lt;int&gt; &lt;int&gt;
## 1 4b5630ee914e848e8d07221556b0a2fb 2019-07-09 15:23:23         0     1
## 2 4b5630ee914e848e8d07221556b0a2fb 2019-03-21 04:14:59         0     0
## 3 4b5630ee914e848e8d07221556b0a2fb 2019-02-25 07:19:44         0     1
## 4 4b5630ee914e848e8d07221556b0a2fb 2019-01-29 01:17:44         0     1
## 5 4b5630ee914e848e8d07221556b0a2fb 2019-06-13 21:26:08         0     0
## # … with 5,063 more rows</code></pre>
<p>What if you assigned treatment to sessions instead of to users (see <a href="https://towardsdatascience.com/the-second-ghost-of-experimentation-the-fallacy-of-session-based-metrics-fb65006d30ff">this Skyscanner post</a> for an overview of the problems you’re in for)?</p>
<pre class="r"><code>events_df &lt;- events_df %&gt;% 
  mutate(treatment = rbinom(length(treatment), 1, 0.5),
         click = rbinom(length(treatment), 1, p + beta * treatment))</code></pre>
<p>What’s the difference between these two datasets?</p>
<pre class="r"><code># with user ids
events_df %&gt;% print(n = 3)
## # A tibble: 5,068 x 4
##   id                               session             treatment click
##   &lt;chr&gt;                            &lt;dttm&gt;                  &lt;int&gt; &lt;int&gt;
## 1 4b5630ee914e848e8d07221556b0a2fb 2019-07-09 15:23:23         0     1
## 2 4b5630ee914e848e8d07221556b0a2fb 2019-03-21 04:14:59         0     0
## 3 4b5630ee914e848e8d07221556b0a2fb 2019-02-25 07:19:44         1     0
## # … with 5,065 more rows

# session id only
events_df %&gt;% select(-id) %&gt;% print(n = 3)
## # A tibble: 5,068 x 3
##   session             treatment click
##   &lt;dttm&gt;                  &lt;int&gt; &lt;int&gt;
## 1 2019-07-09 15:23:23         0     1
## 2 2019-03-21 04:14:59         0     0
## 3 2019-02-25 07:19:44         1     0
## # … with 5,065 more rows</code></pre>
<p>In the first case, even though you randomized over sessions instead of users, at least you have the user ids in the first dataset and you might be able to correct for within-user session dependence. If you don’t have the users, you might be in trouble.</p>
</div>
</div>
<div id="so-much-more" class="section level2">
<h2>So much more!</h2>
<p>A huge part of of data science for consumer products is understanding the user experience. If you think you understand the user experience, can you model it? If you think of a pattern in or problem with the experience, can you model it? If not, what makes you think you can design an experiment to test it, or design an experiment to account for it?</p>
<p>Think about what your experience when you use twitter:</p>
<ol style="list-style-type: decimal">
<li>you’re in a meeting and you can’t check twitter for two hours</li>
<li>you turn on twitter, you see a tweet from a friend, respond and close twitter</li>
<li>you get reply/like notifications</li>
<li>you turn on twitter again right away</li>
</ol>
<p>Can you imagine the time dependence / autocorrelation in the pattern of your actions? You have no activity for a long time, but once you turn it on, you turn it on and off and on again consistently until the conversation is over. Thinking through the user experience, then simulating data and a possible experiment is a great way to practice solving A/B testing problems.</p>
</div>
