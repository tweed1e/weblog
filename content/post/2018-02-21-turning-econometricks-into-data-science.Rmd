---
title: turning econometricks (into data science)
author: ~
date: '2018-02-21'
slug: turning-econometricks-into-data-science
categories: []
tags: []
description: ''
draft: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, 
                      warning = FALSE, 
                      message = FALSE,
                      fig.height = 4, fig.width = 8)
```

## f(econometrics + data science) > f(econometrics) + f(data science)



Econometrics and data science (and applied statistics) have a lot in common, but I find myself spending a lot of time translating problems and methods to and from different statistical languages (and I don't mean translating from Stata to R and back). In econometrics, *consistency* is your number 1 goal. Number 2 is unbiasedness, and number 3 and 4 are statistical and economic significance. Consistency and unbiasedness are hard without experiments.

But because data science is either uncorncerned with causality and random assignment (e.g., label images) or gets it for free (via A/B testing), 90% of my econometrics education gets thrown out the window. But I don't have to re-learn stats via biostats or sociology or medicine to be a great data scientist, I just have to translate my understanding.

## A/B testing

The biggest step in translating from econometrics to A/B testing is *just doing it*. Find experimental data, and compare typical A/B testing methods to econometric methods.

But experimental data isn't common. So one can practice prediction problems on [kaggle]() till the cows come home but you can't do basic experimental stats. But you have R, and you have fingers, so just make up some experimental data! Which is even better, because you can tell what your answers are supposed to be!

## Simulate a fake experiment

``` {r, eval = FALSE}
library(tidyverse)
library(viridis)

# do things 

```